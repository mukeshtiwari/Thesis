\chapter{Theorem Prover and Cryptography}
\label{cha:theorem_crypto}
 

A proof assistant or theorem prover is a computer program which assists users in development 
of mathematical proofs. Basically, the idea of 
developing mathematical proofs using computer goes back to Automath (automating mathematics)
\citep{deBruijn1983} and LCF \citep{Milner:1972:IAS:942578.807067}. The 
Automath project (1967 until the early 80's)  was initiative of De Bruijn, and the aim of the project was to 
develop a language for expressing mathematical theories which can be verified by aid of computer.  
Moreover, the Automath was first 
practical project to exploit the Curry-Howard isomorphism (proofs-as-programs and formulas-as-types). 
DeBruijn  was likely unaware of this correspondence, and he almost re-invented it.
The Automath project can be seen as the precursor of
 proof assistants NuPrl \citep{Constable:1986:IMN:10510} and Coq \citep{Bertot:2004:ITP}.  
 Some other notable  proof assistants are 
 Nqthm/ACl2 \citep{507872}, PVS \citep{Owre:1992:PPV:648230.752639},
 HOL (a family of tools derived from LCF theorem prover) \citep{Slind:2008:BOH:1459784.1459792}
 \citep{Harrison:1996:HLT:646184.682934} \citep{Nipkow:2002:IHP},
 Agda \citep{Norell:2008:DTP:1813347.1813352}, and Lean \citep{10.1007/978-3-319-21401-6_26}.


\textbf{Chapter overview:}
 This chapter is overview of Coq theorem prover and Cryptographic primitives. 
 In the section \ref{sec:problemstatement}, I will give a brief overview of 
 theoretical foundation, calculus of construction (\ref{sec:cc}) and calculus of inductive 
 construction (\ref{sec:cic}), of Coq.  In the section \ref{sec:typeprop}, I will discuss about 
 \texttt{Type} and \texttt{Prop}
 which is very crucial from program extraction point of view.  Our goal during 
 this course of formalization was not only proving the correctness of 
 Schulze method, but extracting a executable OCaml/Haskell code to count 
 ballots.  In the section \ref{sec:deplambda}, I will focus 
 on dependent types and  how it leads to correct by construction paradigm
 by designing a  type safe printf function. 
 Section \ref{sec:gallina} focuses on Coq specification language 
 \texttt{Gallina} with a example showing that why writing proofs using  
 \texttt{Gallina} is difficult and cumbersome, and how it can be eased by 
 using tactics. Finally, in the section  \ref{sec:coqproof}, we will take 
 philosophical route to justify that why should we trust in Coq proofs 
 even though they do not appear anywhere near to a proof written by 
 a human. 


\section{Coq: Interactive Proof Assistant}
\label{sec:problemstatement}
Coq  is an interactive proof assistant (theorem prover) based on
theory of Calculus of 
Inductive Construction \citep{Paulin-Mohring:1993:IDS:645891.671440} which itself is an 
augmentation of Calculus of Construction 
\citep{Coquand:1988:CC:47724.47725} with inductive data-type.  
 

\subsection{Calculus of Construction}
\label{sec:cc}
\subsection{Calculus of Inductive Construction}
\label{sec:cic}
%\fix{Flesh out the details of 
% Calculus of construction and Inductive construction}
% \fix{Write here about syntax and semantics of CIC}
 
 
\subsection{Type vs. Prop: Code Extraction}
\label{sec:typeprop}
 \fix{explain here the difference between Prop and Types. How it affects 
  the code extraction }
  It's good starting point to tell the reader that we have two definitions, 
  one in type and other in prop. Why ? Because Type computes, but it's
  not very intuitive for human inspection while Prop does not compute, 
  but it's very intuitive for human inspection. We have connected that 
  the definition expressed in Type is equivalent to Prop definition. 
  
  \subsubsection{Reification}
  \label{sec:reification}
    
 \subsection{Correct by Construction: Type Safe Printf}
 \label{sec:deplambda}
  One of the highly sought feature of Coq is dependent type, 
  a type which is parametrised by value.  
  The expressiveness of dependent type make it possible
  to express specification at type level, and these specifications enables larger 
  set of  logical errors to eliminated at compile time. 
  
 
 Using the expressiveness of dependent type, we construct a type-safe version of 
 printf. Our goal is to generate compiler error when the given format string and the type of 
 corresponding input values  
 do not match, e.g. printf "\%d \%s" "hello Coq" 42 should be compiler error because
 \%d is a directive for integer value, but the type of input, "hello Coq", is string. In addition, 
 type-safe printf should print the input when the format string is aligned with type of input, e.g.
 printf "\%s \%d" "hello Coq" 42 should print the string "hello Coq  42" because the first directive 
 of format string, \%s, and type of input, "hello Coq", is aligned. Similarly, the second directive 
 of format string, \%d, is also aligned with the type of input, 42.
 
 The high level idea is to split the printf arguments into two parts: i) format string, 
 and ii) values to be printed. For example, printf "\%s \%d" "hello Coq" 42 would be split into "\%s \%d", and 
 "hello Coq" 42.  Based on the format string, we design two functions: i) a type level function, 
 and ii) a value level function. The type level function would 
 take format string and returns a variadic function type, e.g. 
 on format string "\%s \%d", it would return a function type with 
 signature \texttt{string -> Z  -> string}.
 The value level function, whose type signature 
 is constructed by the type level function, would take the values to printed as input. If the 
 type of values to be printed is aligned with the type constructed by the type level function then 
 we proceed to print the string, otherwise we generate compiler error.  
 


First, we defined a abstract syntax tree, \textit{format}, to make it explicit the characters we 
are interested in format string. Additionally, the \textit{format\_string} function takes the format string 
and returns the abstract syntax tree, and the type level, \textit{interp\_format}, takes the 
abstract syntax tree and returns the function type corresponding to format string.

\begin{verbatim}
(* abstract syntax tree *)
Inductive format :=
| Fend : format
| Fint : format -> format
| Fstring : format -> format
| Fother : ascii -> format -> format.

(* turn the format string into abstract syntax tree *)
Fixpoint format_string (inp : string) : format :=
  match inp with
  | EmptyString => Fend
  | String ("%"%char) (String ("d"%char) rest) => Fint (format_string rest)
  | String ("%"%char) (String ("s"%char) rest) => Fstring (format_string rest)
  | String c rest => Fother c (format_string rest)
  end.


(* construct the type level function from abstract syntax tree *)
Fixpoint interp_format (f : format) : Type :=
  match f with
  | Fint f => Z  -> interp_format f
  | Fstring f => string -> interp_format f
  | Fother c f => interp_format f
  | Fend => string
  end.
\end{verbatim}


\noindent
The \textit{interp\_format} function returns a function type 
(\texttt{Z -> string -> string -> string})  on the (abstract syntax tree of) 
format string "\%d \%s \%s" 

\begin{verbatim}
Eval compute in interp_format (format_string "%d %s %s").
(* = Z -> string -> string -> string
     : Type *)
\end{verbatim}

Now, we construct a value level function, \textit{interp\_value}, whose type 
is constructed by type level function, and it will take the values to be printed as input.
The type of values to print should match the type constructed by type level 
function for successful type checking otherwise it will be type error. 

\begin{verbatim}
(* value level function whose type is constructed on fly by interp_format 
    function *)
Fixpoint interp_value (f : format) (acc : string) : interp_format f :=
  match f with
  | Fint f' => fun i => interp_value f' (acc ++ of_Z i)
  | Fstring f' => fun i => interp_value f' (acc ++ i)
  | Fother c f' => interp_value f' (acc ++ String c EmptyString)
  | Fend => acc
  end.
\end{verbatim}

\noindent
Finally, we define the printf function, and evaluate it on two inputs: 
i)  printf "\%d \%s" "hello Coq" 42, and ii)  printf "\%d \%s" 42 "hello Coq".

\begin{verbatim}
Definition printf s := interp_value (format_string s) "".           

Eval compute in  printf "\%d \%s" "hello Coq"%string 42.
(* Error: The term ""hello Coq"%string" has type "string" 
while it is expected to have type "Z". *)

Eval compute in  printf "\%d \%s" 42 "hello Coq"%string. 
(*  "\0b101010 \hello Coq"%string. The number 
42 is printed in binary *)                            
\end{verbatim}
The first input, printf "\%d \%s" "hello Coq" 42, is type error because 
printf "\%d \%s" returns a value level function whose  type is Z -> string -> string, but 
the type of first argument, "hello Coq", is string which does not unifies with Z,
while second one is successfully printed as string. 

  
  

 
 \subsection{Gallina: The Specification Language}
 \label{sec:gallina}
  The example, type safe printf function, I gave in previous 
  section was encoded in Coq's specification language Gallina. 
  Gallina is a highly expressive specification 
  language for development of mathematical theories and proving the    
  theorems about these  theories; however, writing proofs in Gallina
  is very tedious and cumbersome. Furthermore, It is not suitable for large proof 
  development. In order to ease the proof development, Coq also provides 
  tactics.  The user interacting with Coq theorem prover applies these 
  tactics to build the  Gallina term  which otherwise would  
  be very laborious.
  
 We have written two proofs that addition on natural number is commutative. 
 First proof, \textit{addition\_commutative\_gallina}, is written using 
 Gallina, while the second proof, \textit{addition\_commutative\_tactics}, is written 
 using the tactics.  In general, we write programs directly in Gallina and use tactics 
 to prove properties about the programs. However, there is no fixed set of rules, and tactics 
 can be used to write programs with dependent types (which we have done during this
 formalization).
 
\begin{verbatim}
(* proof written using Gallina *)
Lemma addition_commutative_gallina : forall (n m : nat), n + m = m + n.
refine
      (fix Fn (n : nat) : forall m : nat, n + m = m + n :=
        match n as n0 return (forall m : nat, n0 + m = m + n0) with
        | 0 => fun m : nat => 
           eq_ind_r (fun n0 : nat => m = n0) eq_refl (Nat.add_0_r m)
        | S n' =>
          fun m : nat =>
            eq_ind_r (fun n0 : nat => S n0 = m + S n')
                     (eq_ind_r (fun n0 : nat => S (m + n') = n0) 
                     eq_refl (Nat.add_succ_r m n')) (Fn n' m)
        end).
Qed.

(* proof written using tactics *)
Lemma addition_commutative_tactics : forall (n m : nat), n + m = m + n.
  induction n; intro m; simpl; try omega.
Qed.
\end{verbatim}



 \subsection{Trusting Coq proofs}
 \label{sec:coqproof}
  In general, Coq proofs are nowhere similar to a mathematical 
  proof written by trained mathematician. Also, these proofs 
  are verbose and fairly long, so a 
  very fundamental question is: why should we 
  accept or believe in a proof written in Coq \citep{pollack1998believe}?  Generally, the answer of 
	accepting or trusting Coq proos is two fold:
  i) is the logic (CIC) sound?, and ii) is the implementation correct?
  The logic has already been reviewed by many peers and proved correct 
  using some meta-logic, therefore the answer of our question about trusting Coq proof 
  hinges on the implementation. 
  Coq implementation (written in OCaml)  has two parts, the type checker (small kernel), 
  and tactic language to build the proofs.
  We lay our trust in type checker, because it's small kernel and can be 
  manually inspected. Furthermore, if there
  is a bug in tactic language, which often is the case, then build proof would 
  not pass the type checker.  Also, we can use the publicly available proof 
  checkers written by experts and inspected by many others. In addition, to increase the 
  confidence, there have been 
  efforts to certify type checker \citep{Appel2003}
  \citep{barras1996coq}, verifying meta theory of one proof system 
  in other \citep{10.1007/978-3-319-08970-6_3}, self certificate of 
  theorem prover \citep{10.1007/11814771_17}. However, no system can 
  prove its own consistency (G{\"o}del's second incompleteness theorem), therefore
  trusting human judgement is inevitable.
  
 
\section{Cryptography}
    The word cryptography comes from the two Greek words: 
    \textit{krypt\'{o}s}, meaning \textit{hidden}, and \textit{gr\'{a}fein} meaning \textit{to write}. As a matter of 
    fact, in the past, hidden writing (cryptography), using the symbol replacement, has been used 
    to conceal the message. For example,
    the earliest known usage of cryptography (symbol replacement) goes back to  ancient 
    Egyptian (Khnumhotep {\rm II}, 1500 BCE); however, the purpose of replacing one symbol by other 
    was not to protect
    any sensitive information but to enhance the linguistic appeal. The first known usage of 
    cryptography to conceal the sensitive information goes back Mesopotamians (1500 BCE) where 
    they used it to hide the formula for pottery glaze. Fast forward, around 100 BCE, 
    Julius Caesar wrote a letter to Marcus  Cicero using a method, now known 
    as Caesar cipher, which would shift each character in letter by 3 position right with wrapping 
    around, i.e. X would wrap A, Y would wrap to B, and Z would wrap to C. Decryption was 
	3 character left shift.  Using the  tools of modern mathematics, encryption and decryption 
	in \textit{Caesar cipher} is modular addition and modular subtraction (modulo 26), respectively.  
    Overall, cryptography is art and science of making thing  unintelligible from everyone, except the 
    intended recipient.  	
	    
	The modern cryptography originated in 1970 with two ingenious ideas, \textit{Data Encryption Standard (DES)}, 
	and \textit{Diffie-Hellman Algorithm}. Data Encryption Standard, developed at IBM in 1970, is a symmetric 
	key encryption algorithm which uses the same key for encryption and decryption. Since its inception, Data Encryption Standard
	amassed a bad reputation because of \textit{National Security Agency (NSA)} involvement; however, it had a 
	a practical problem, key management (sort of chicken egg problem). If two parties wanted to communicate
	securely over insecure channel using Data Encryption Standard, then they needed to agree on a common key. 
	In order to agree on common key, they needed a secure channel where they can securely communicate the key. 
    The solution to this problem came from \textit{Diffie-Hellman} key exchange where two parties can exchange the 
    key securely over insecure channel. Moreover, the advent of \textit{Diffie-Hellman} key exchange started the 
    whole new area of public key cryptography where encryption and decryption key are different. 
    Although \textit{Diffie-Hellman} key exchange suffers from  man-in-the-middle (MITM)  attack if used for keys exchange in its 
    naivety, e.g. Logjam \citep{Adrian:2015:IFS:2810103.2813707}, nonetheless, 
    it is a building block for many other algorithm, e.g. ElGamal Encryption \citep{elgamal1985public}. 
    
    
    
    In this thesis, we are mostly concern about public key cryptography and will no longer discuss or explain 
    symmetric key cryptography, hence any mention of cryptography hereafter should be assumed as
    public key cryptography. 
    The basic working principals of modern day cryptography is based on 
    mathematical principal than vanilla symbol replacement. 
    In addition, it is no longer just 
    used to achieving confidentiality, but various other things, e.g. integrity,  authentication, non-repudiation 
    protocol, digital signature, digital cash, etc.
    These mathematical principal involves 
    various algebraic structures and algorithm to manipulate the object from these structures.
    For example, the underlying mathematical principal of \textit{Diffie-Hellman}  algorithm 
    is hardness of computing discrete logarithm in finite field. \fix{We will discuss more about these
    structures in  chapter 7}.
    
    
    
    
%    
%    The current form of cryptography mostly 
%    developed in 1970. Moreover, the basic principals of modern day cryptography, cryptography hereafter, is based on 
%    mathematical principals than vanilla symbol replacement.  Moreover, It has three distinct 
%    element:
%    \begin{itemize}
%    \item data (plaintext data and ciphertext data)
%    \item algorithm (encryption algorithm and decryption algorithm)
%    \item key (encryption key and decryption key)
%    \end{itemize}
%    
%    Depending on the distinction between the key, encryption key and decryption key, 
%    used in the process, the cryptography can be 
%    divided into two categories: (i) symmetric key cryptography where the 
%    same key is used for encrypting the plaintext data to ciphertext  data, and decrypting 
%    the ciphertext data to plaintext data, e.g. \texttt{Data Encryption Scheme}  
%    (ii) asymmetric (public) key cryptography where 
%    two different keys, public key and private key, are used for encrypting the plaintext 
%    data into ciphertext data and ciphertext data to plaintext data, e.g. \texttt{Diffie-Hellman algorithm} 
%   Since 1970, the cryptography has evolved, and now, it is not only used for confidentiality, but 
%   for integrity, authentication and non-repudiation
%   
%   The mathematical foundations of cryptography lies in algebraic group
%   \begin{itemize}
%     \item Group
%     \item Field 
%     \item Vector 
%    \end{itemize}
%    
%    which we will discuss more in Chapter 7. 
    
%    In this thesis, we are concern with public key cryptography.
    
    Now we  describe the workings of \texttt{Diffie-Hellman} \citep{Diffie:2006:NDC:2263321.2269104}
    algorithm, because all the constructions we have used  are based on \texttt{Diffie-Hellman} construction. 
    Before we describe the algorithm, we briefly sketch the algebraic structure Group because it is underlying algebraic structure of 
    \texttt{Diffie-Hellman}  construction  (typically, the underlying 
    structure is multiplicative group of a finite field). Also, note that our definition is influenced theorem-provers/type-theory because 
    we have  written the type signature of group operator $*$ and inverse operator $inv$. 
    
    \subsection{Group}
    A group is a set $G$, with a binary operator $* : G \rightarrow G \rightarrow G$, identity element $e$, and inverse operator $inv : G \rightarrow G$ such 
    that the following laws hold: 
    \begin{itemize}
     \item \texttt{Associativity}: $\forall$  a b c $\in G,$  $a * (b * c) = (a * b) * c$
    \item \texttt{Closure}: $\forall$ a b $\in G,$  $a * b \in G$
    \item \texttt{Inverse Element}: $\forall$ a $\in G$ $\exists$ $a^{-1} \in G$, such that $a * a^{-1} = a^{-1} * a = e$. $a^{-1}$ is called inverse of a (
     $inv$ $a$).
    \item \texttt{Identity}: $\forall$ a $\in G,$  $a * e = e * a  = a$
    \end{itemize}
   
    \noindent
    Furthermore, if a group is commutative, i.e. 
    $\forall$ a b $\in  G,$  $a * b = b * a$, then we call it abelian group (in honour of Niels Henrik Abel). In addition, 
    if a \textit{group} is \textit{cyclic group} if it can be generated by a single element, also known as generator of group 
    and denoted as $g$, by repeatedly applying the group operator $*$ to itself. Moreover, a group is \textit{finite cyclic group}
    if it is cyclic and the cardinality of the underlying set (carrier set) $G$ is finite. The cardinality is also known as order of group. 
	    
    
     
     \subsection{Diffie-Hellman Construction}
     	Now we explain \texttt{Diffie-Hellman} construction. The construction can be divided into two steps:
		\begin{enumerate}
		\item The two communicating parties, say Alice and Bob, agree with shared public parameters which 
		are finite cyclic group $G$ of order $p$ ($p$ is a large prime) and generator element $g$.
		\item After agreeing with public parameters, Alice and Bob initiates the key exchange protocol (assuming that 
		 Alice goes first):
		 \begin{enumerate}
		   \item Alice selects a random element $a$ from the $G$, computes $g^{a}$ ( $g * g * g ... * g$  $a$ times), and shares 
		   $g^{a}$ to Bob. 
		   \item Similarly, Bob selects are random element $b$ from the $G$, computes $g^{b}$, and shares  $g^{b}$
		   with Alice.
		   \item Finally, Alice computes the key $(g^{b})^{a}$, and Bob computes the key $(g^{a})^{b}$.  Because group exponentiation is 
		   a commutative operator, both, Alice and Bob, have the common key $g^{ab}$. 
		   
		 \end{enumerate}
      \end{enumerate}		
      
     
      \noindent
       During the whole process, Eve, the adversary, would have $g^{a}$ and $g^{b}$, but she can not compute the 
      $ g^{ab}$ from these two values assuming that discrete logarithm is hard to compute. 
      There are, off course, other attacks exists, e.g. denial of man in the middle attack, Logjam, etc. 
      The security property of \texttt{Diffie-Hellman} construction is formalized using complexity theoretic notion 
      given below (we would not go into the details of complexity theoretic notions):
      
     
      \textbf{DL - Discrete Logarithm problem:} 
      An instance of \textit{DL} problem states that given a finite cyclic group $G$, a generator of $g$ of $G$, and 
      an element $y$, finding an element $x \in G$ such that $g^{x} = y$.
      
      
      \textbf{DH - Diffie-Hellman problem:}
      An instance of \textit{DH} problem   
      states that given a finite cyclic group $G$, a generator of $g$ of $G$, 
      elements $g^{a}$ and $g^{b}$, finding the element $g^{ab}$.
      
      
      \textbf{DDH - Decision Diffie-Hellman Problem:}
      An instance of \textit{DDH} problem states that given a finite cyclic group $G$, a generator of $g$ of $G$,
      elements $g^{a}$, $g^{b}$, and $g^{c}$, determining if $c = a * b$.
      
           	 
     
     \subsection{El-Gamal Encryption Scheme}
     In 1985, Tahir El-Gamal \citep{elgamal1985public} proposed a new encryption system which was based on Diffie-Hellman algorithm. 
     \textit{El-Gamal} turned the interactive  Diffie-Hellman algorithm into a non-interactive, no need for any active second party, by introducing 
     a randomness.  The \textit{ElGamal} scheme has three phases:
     \begin{enumerate}
		\item \textbf{Key Generation:}   
		The user, say Alice, first chooses a finite-cyclic group $G$ of order $p$ ($p$ is a large prime) and a group group generator $g$.
		She randomly selects a an element $x$ from group the group $G$ as a private key, computes her public key $h = g^{x}$. 
		Subsequently, she publishes 
		the <$G$, $g$, $p$, $h$> and keeps $x$ private. 
		\item \textbf{Encryption:}
		If any party, say Bob, wants to send a encrypted message $m$ to Alice, then he would randomly select an element 
		r  (1 <= r < p) from the group $G$, computes $c_{1} := g^{r}$ and $c_{2} := m * h^{r}$, and send the pair ($c_{1}, c_{2}$) to 
		Alice. 
		\item \textbf{Decryption:}
		Upon receiving any pair ($c_{1}, c_{2}$), Alice would compute $c_{2} * c_{1}^{-x}$. A basic simplification of $c_{2} * c_{1}^{-x}$
		shows that it recovers the plaintext message. The simplification proceeds by replacing the $c_{2}$ with 
		$m*h^{r}$ and $c_{1}$ with $g^{r}$ in $c_{2} * c_{1}^{-x}$. This substitution leads to 
		$m * h ^ {r} * g^{-rx}$ which upon further simplification by replacing the $h$ with $g^{x}$
		leads to $m * g^{xr} * g^{-rx}$. Using the same base rule, the term $m * g^{xr} * g^{-rx}$ can be 
		written as $m * g^{xr - rx}$. Since, the underlying group, $G$, is a abelian group, so we 
		can replace $m * g^{xr - rx}$ with $m * g^{0}$. The term $g^{0}$  = $e$ (the identity of group $G$) and using 
		the right identity group law, we can replace $m * e$ by $m$. 
		
		
    
    \subsection{Homomorphic Encryption}
	     Homomorphic encryption  is a encryption scheme which allows us to perform useful operation on 
	     encrypted data without decrypting the data.
	     It was first posed by Rivest, Adleman and Dertouzos in \citep{rivest1978data}: 
	     \begin{displayquote}
	     
	     Consider a small loan company which uses a commercial time-sharing service to store its records.  
	     The loan company’s "data bank" obviously contains sensitive information which should be kept private.  
	     On the other hand, suppose that the information protection techniques employed by the time sharing 
	     service are not considered adequate by the loan company.  In particular, the systems programmers would 
	     presumably have access to the sensitive information.  The loan company therefore decides to encrypt all 
	     of its data kept in the data bank and to maintain a policy of only decrypting data at the home office -- data 
	     will never be decrypted by the time-shared computer.
	     
	     \end{displayquote}  
	     
		A encryption scheme is homomorphic if for any two plaintext $x$ and $y$:
		\begin{displayquote}
		
		 $Enc(x) \bigotimes Enc(y) = Enc (x \bigoplus y)$  where 
		$Enc$ is encryption function, $\bigotimes$ is operation on ciphertext, and $\bigoplus$
		 is operation on plaintext.
		
		\end{displayquote}
				
		These two operators $\bigotimes$ and $\bigoplus$ are very specific. If a cryptosystem that supports an arbitrary 
		function $f$ on ciphertext, then it is called fully homomorphic cryptosystem:
		\begin{displayquote}
		  $ f (Enc(m_{1}), Enc(m_{2}), ..., Enc(m_{k}) = Enc( f (m_{1}, m_{2}, ..., m_{k}))$ 
	    \end{displayquote}
		
		\noindent
		The first fully homomorphic encryption system was proposed by Craig Gentry \citep{Gentry:2009:FHE:1834954}; however, 
		in this thesis we are mostly concern with partially homomorphic encryption (either additive or multiplicative, but not both),
		specifically additive ElGamal, 
		so we are not going to present the details overview 
		of Craig Gentry fully homomorphic construction. From now on, we would be using homomorphic encryption for 
		partially homomorphic encryption. 
		 	    
	    
	    
	    
	     
	    Now that, keeping in mind that homomorphic encryption enables us to perform useful operation on encrypted data, 
	    we will see what kind of homomorphic property is exhibited by the ElGamal method discussed in the previous section. 
	    Given a public infrastructure <$G, p, g, h$> for ElGamal scheme, 
	     we encrypt two message $m_{1}$ and $m_{2}$ by taking two random numbers $r_{1}$,  $r_{2}$ from the group:
	     \begin{displayquote}
	     $Enc(m_{1}, r_{1}) := (g^{r_{1}}, m_{1} *  h^{r_{1}})$ 
	      \end{displayquote}
	     
	     \begin{displayquote}
	     $Enc(m_{2}, r_{2}) := (g^{r_{2}}, m_{2} *  h^{r_{2}})$ 
	      \end{displayquote}
	     
	     
	     If we mutiply these two cipher together pairwise, we get ($g^{r_{1}+ r_{2}}, m_{1} * m_{2} *  h^{r_{1} + r_{2}}$). 
	     After decrypting this combined ciphertext, we will get $m_{1} * m_{2}$. In the scheme, $\bigotimes$ is multiplication and 
	     $\bigoplus$ is also multiplication. Furthermore,  
	     if our end goal is  to achieve multiplication on a bunch of plaintext, then rather than decrypting the corresponding ciphertext individually 
	     and multiplying them, we could simply multiply all the ciphertext together and decrypt the final result.  
	     The advantage of this scheme is that it does not leak the individual values which, sometimes, is a very crucial property in many 
	     application, specifically election voting.
	     In electronic voting protocols, we do not want to reveal the choices of a individual voter, but it is acceptable to reveal the final tally. 
	     However, this scheme is not suitable for electronic voting schemes because it is multiplicative. Almost, to the best of 
	     my knowledge, all the electronic voting scheme calculate the finally tally by adding the individual choices of all
	     voters, so the requirement is achieve the addition on plaintext. 
	     There are 
	     many additive homomorphic encryption schemes, e.g. Benaloh cryptosystem, Paillier cryptosystem, etc. In addition, we 
	     can modify the ElGamal encryption scheme to make additive. In additive case, it works as:
	       \begin{displayquote}
	      $Enc(m_{1}, r_{1}) := (g^{r_{1}}, g^{m_{1}} *  h^{r_{1}})$ 
	      \end{displayquote}
	     
	     \begin{displayquote}
	    $Enc(m_{2}, r_{2}) := (g^{r_{2}}, g^{m_{2}} *  h^{r_{2}})$ 
	      \end{displayquote} 
	     
	    
	     
	    
	      \noindent
	      Multiplying these two ciphers pairwise would give us,  ($g^{r_{1} + r_{2}}$, $g^{m_{1} + m_{2}} * h^{r_{1} + r_{2}}$) which would decrypt as 
	      $g^{m_{1} + m_{2}}$. In this case, $\bigtimes$ is multiplication and $\bigoplus$ is addition.  We can calculate the value 
	      of $m_{1} + m_{2}$ by using linear search algorithm, or more efficient one 
	      Pohlig–Hellman algorithm. 
	      However, the downside 
	      of this scheme is that if the values of $m_{1} + m_{2} + \dotsb + m_{n}$ (assuming n values) is very large, then calculating it from 
	      $g^{m_{1} + m_{2} + \dotsb  + m_{n}}$ is 
	      not very practical \citep{10.1007/3-540-69053-0_9}. 
	     
     \subsection{Zero Knowledge Proof}
      In conventional mathematics, a proof of mathematical statement is collection of basic axioms combined according to rules of 
      the system. For example, we want to prove that in for any group (G, *), for any two elements x y $\in$ G, we have:
      \begin{displayquote}
		 
		 $(x * y)^{-1}$ = $y^{-1} * x^{-1}$
		
	    \end{displayquote}
      
      \noindent
      Proof: we assume arbitrary x, y. We show that $(x * y)^{-1}$ and $y^{-1} * x^{-1}$ are 
      inverse of each other by combining them together using the group operator $*$ and using 
      the group laws lead to the identity of the group $G$.
 
 \begin{align}
(x * y) * (y^{-1} * x^{-1})&=  x * y * y^{-1} * x^{-1}  (associativity) \nonumber \\
                     &= x * (y * y^{-1}) * x^{-1}   (associativity) \nonumber \\
                     &= x * e  * x^{-1} (inverses) \nonumber \\
                     &=  x  * x^{-1} (identity)   \nonumber \\
                     &= e (inverse) \nonumber \\
\end{align}

     \noindent
      Similarly, we can prove that $((y^{-1} \cdot x^{-1}) \cdot   (x \cdot y) = e $.
      We can also formalize it inside theorem prover and prove it more formally (below is a proof in Coq theorem prover).
      
      \begin{verbatim}
      Lemma inv_distr : forall a b, inv (f a b) = f (inv b) (inv a).
      Proof.
        intros a b. symmetry. 
        apply inv_uniq_l.
        rewrite <- assoc.
        rewrite  (assoc (inv b) (inv a) a).
        rewrite (inv_l a).
        rewrite (assoc (inv b) e b).
        rewrite (id_l b).
        rewrite (inv_l b). auto.
      Qed.
      \end{verbatim}
     
     If a verifier wants to verify the correctness of our proof, then he would simply check that if the group rules are applied correctly. 
     Moreover, these proofs 
     are static in nature, i.e. once the prover has produced the proof, then the content of proof is not going to change over time, and
     there would not be any interaction between prover and verifier if verifier wants to verify the proof.  In addition, the verifier 
     not only learned that the statement is true, but he also learned the content of proof (gained some knowledge).
     
     In contrast, zero-knowledge-proof, first introduced by Goldwasser, Micali, and Rackoff \citep{Goldwasser:1985:STOC} , 
     is probabilistic proof that involves the explicit notion of a interaction between 
     the prover and verifier. In addition, 
     the goal of the prover is to convince the verifier about the validity of some statement without revealing any information, i.e. 
     the only thing verifier would learn is that if statement is true or false without any other information. 
     More formally, zero-knowledge-proof for a language $L \in \{0, 1\}^{*} $ (generally NP) is a interactive proof  
     between a (computationally unbounded) prover $P$ and a (polynomial time) verifier $V$. Furthermore, 
     the goal of $P$ is to convince V that x $\in$ L  such that:
   
     \textbf{Completeness:} If x $\in$ L then the honest prover $P$ would convince the 
       honest verifier V to accept the claim with overwhelming probability. 
       If $P$ can always convince (probability 1) the $V$ that x $\in$ L, then the proof system has perfect completeness. 
    
     \textbf{Soundness:} If x $\notin$ L then dishonest prover $P^{*}$ can not convince the honest verifier $V$ 
     to accept the claim (with some small probability error known as soundness error)
     
     \textbf{Zero knowledge:} A malicious verifier $V^{*}$ would gain no additional information by interacting with a honest prover $P$ 
      other than x $\in$ L. More formally, for every (polynomial time) program $V^{*}$ there exists a (polynomial time)
      program $S$, also known as simulator, which can produce the transcript of protocol by itself without interactive with anyone. 
      Moreover, the transcript 
      produced by simulator $S$ is indistinguishable from real transcript produced by interaction between 
      
    
    \subsubsection{Zero Knowledge Proof of Knowledge}
    Sometimes, the fact that $ x \in L$ is completely trivial.  For example, for any given finite group $G$ of order $p$ ($p$ is prime), 
    a random element $h$ from the group $G$, and generator $g$of the group $G$, a prover claims that there is a $x$ such that 
    $g^x = h$. 
    This is trivial because we know that there always exists such $x$ (discrete logarithm problem); however, the challenge is to show that
    the prover knows the witness $x$.
    Formally, zero-knowledge-proof of knowledge is defines as: let $R = {(x, w) \subset L x W$ is a binary relation such that     
    $x \in L$ is common string between prover $P$ and verifier $V$ and $w \in W$, also known as witness, is private to 
    the prover $P$.  Moreover, the goal of prover $P$ is to convince verfier $V$ that $(x, w) \in R$ in zero-knowledge.  
        
   
    \subsection{Sigma Protocol}
     Sigma protocols are efficient way to achieve zero-knowledge-proof of a knowledge.   Sigma protocol is 
     a three step communication between a prover $P$ and a verifier $V$ where goal of the prover is to convince the verifier that 
     he knows witness w for common input x such that  $(x, w) \in R$.   
     
     \begin{enumerate}
     \item $P$ sends a message $r$
     \item $V$ sends a random string $e$
     \item $P$ replies with $z$
     \end{enumerate}
     
     Based on public inputs (x, r, e, z), the verifier $V$ decides to accept or reject the proof.   A protocol is 
     said to be sigma protocol for a relation $R$ if: 
     
     \textbf{Completeness:} when prover and verifier follow the protocol for public input $x$ and witness $w$ 
          then verifier accepts the proof
          
      \textbf{Special Soundness:} For a given pubic input $x$, if prover can produce two accepting transcript (a, e, z) 
      and (a, e', z') (e and e' are disjoint), then there exists a efficient program, extractor, which can extract the 
      witness w.
      
      \textbf{Honest Verifier Zero Knowledge:} For a given public input $x$ and random input $e$, there is a simulator 
      which outputs an accepting transcript (a, e, z) which is indistinguishable from a proof generated by 
      a prover interacting with honest verifier. 
     
     A concrete example of sigma protocol is Schnorr protocol \citep{10.1007/3-540-48658-5_19}. In this example, 
     the goal of a prover $P$ is
     to prove the knowledge of discrete log in a Group of order $p$ (p is prime) to a verifier $V$.
     Furthermore, $g$ is the generator of 
     group $G$, $x$ is the public input and $w$ is private input with relation $x = g^w$. The protocol follows:
     
     \begin{itemize}
     \item Prover $P$ randomly selects an element $r$ from [0 $\dotsb$ q), computes $a = g^r$ and sends $a$ to verifier $V$
     \item Verifier $V$ randomly selects an element $c$ from [0 $\dotsb$ q) and sends it to $P$
     \item Prover $P$ sends $z = r + c * w $ to $V$.  $V$ checks $g^{z} = a * x^{c}$
     \end{itemize}
     
     For the protocol described above, all three properties, completeness, special soundness, and honest 
     verifier zero knowledge, hold. 
     \begin{itemize}
      \item Completeness holds with probability $1$. Simplifying the expression $g^{z}$ shows that 
      it is equal to $a * x^{c}$. Replacing the $z$ by $r + c * w$ in expression  $g^{z}$, we get 
      $g^{r + c * w}$.  Using addition rule of power, $g^{r + c * w}$ can be simplified as 
      $g^{r} * g^{c * w}$. First first step of protocol, $a = g^r$, so we can replace the $g^{r} * g^{c * w}$ 
      by $a * g^{c * w}$. From the group infrastructure, we have $x = g^w$, so we can write $x$ at place of 
      $g^{w}$, therefore, $a * g^{c * w}$ transforms into $a * x^c$. 
      
     \item Special soundness holds. For any two given response, 
     $z_{1} = r + w * c_{1}$ and  $z_{2} = r + w * c_{2}$, we can find the witness w by  $(z_{2} - z_{1})/(c_{2} - c_{1})$.
     
     \item Honest Verifier Zero Knowledge also holds. Simulator can always produce a transcript $(g^{z} x^{-c}, c, z)$ by randomly 
     choosing $c$, the random choice $c$ is the reason for special honest verifier zero knowledge, and $z$.
     \end{itemize}
     
   
     \subsection{Commitment Schemes}   
      Commitment schemes are cryptographic primitives equivalent to real life sealed lock-box.
      Once the lock-box is locked and sealed, the content inside it can not be changed without breaking the lock and seal. 
      In general, commitment primitives 
      are backbone of any cryptographic protocol between two parties, communicating over internet, to force them  to  follow the 
      protocol honestly, even they would have a huge gain from deviating 
      from protocol. For example, in order to save some time before a match, Indian cricket team captain, living in Delhi, and Australian cricket 
      team captain, living in Canberra, decide 
      to toss a coin in advance over the Internet, using a mobile application  called toss-app, for a  upcoming series of one-day matches
      \footnote{
      In a cricket match, which is very popular sport in India and Australia, both captains meet in the ground and toss a coin to 
      decide who would have the first call.}.  Assuming the workings of toss-app is naive, i.e. one captain is going to post
      his call in the chat box, and the other other captain is going to toss the coin at their end and post the outcome in chat box. 
      Furthermore, the decision is taken based on the messages posted by the two captains. In this scenario, we are assuming that 
      the captain, who is tossing the coin, is honest and posting the outcome of the coin honestly in the chat box, which could or 
      could not be the case.  The question is can we devise some scheme which would force the both parties to behave honestly? 
      The answer is yes, we can devise such scheme. We would use the sealed lock-box concept, albeit the digital one. Moreover, 
      the first captain would put his call in digitally sealed lock-box and post it in the chat box. Because it is sealed and 
      locked, the other captain would have no idea what is the content inside it. Furthermore, it is impossible to break 
      the lock box, so it is fruitless and waste of time for the other captain to even try. The other captain will toss the coin 
      and post the outcome in a separate digital sealed lock box. Now that we two digital sealed lock box which can 
      only be opened by the respective owners, they would move for the next phase of coin tossing  called revealed phase. 
      In the revealed phase, they both would open their sealed locked box to show that what they have locked, 
      and the decision would be taken accordingly \footnote{Story influenced by Manuel Blum's coin flipping by telephone}. 
      
      
      Formally, a commitment scheme is two step protocol between a sender $S$ and a receiver $R$:
      \begin{enumerate}
      \item Commit phase: sender $S$ commits a value $m$ by generating a random number $r$ and using some algorithm $C$, which takes the message 
      and random $r$. Moreover, the committed value produced by the commitment algorithm $C$, $c = C(m, r)$, is shared with receiver $R$.
      \item Reveal phase: In the reveal phase, the sender reveals the message $m$ and randomness $r$ which are subsequently used by 
         receiver to verify the result, i.e. the receiver computes  $c' = C(m, r)$ and matches it again the given $c$ in the commit phase of protocol. 
      \end{enumerate}
      
      
    \textbf{Security Properties:} 
     Commitment schemes have to have two properties: hiding and binding. Hiding property ensures that 
     the receiver can not recover or recompute the original message $m$ from the given commitment $c$, i.e. 
     it forces the receiver to behave honestly in the protocol. 
     Furthermore, binding property ensures that it is impossible for sender to come up with 
     another message $m'$ which is different from $m$ but produces the same commitment $c$, i.e. 
     it forces the sender to behave honestly in the protocol. 
     
    \textbf{Pedersen commitment:}
     Finally, we give a brief overview of a Pedersen commitment scheme which is based on discrete log.  The protocol as follows assuming 
     the public parameter available to sender and receiver, i.e. the set up has been conducted to generate the the public parameter, 
     and both parties have these values. These values include a prime $p$, $y$ a randomly chosen element from $Z_{p}^{*}$, and $g$ 
     a randomly chosen generator from   $Z_{p}^{*}$.  
     
     \begin{itemize}
     \item Commit phase: The sender generates a random $r$ from $Z_{p}^{*}$, computes commitment $c = g^{r}*y^{m}$ and sent the commitment to 
        receiver
      \item Verification phase: In verification phase, the sender reveals the original message $m$ and the randomness $r$. Finally, 
            the receiver computes  $g^{r}*y^{m}$. If the computed  value matches with the commitment received in 
            commitment phase, then she accepts it otherwise reject it. 
     
	\end{itemize}      



\section{Summary}
In this chapter, we gave a brief summary of Coq theorem prover and cryptographic notation needed to understand the further chapters. By no means, 
these descriptions were exhaustive. For a detailed treatment of Coq theorem prover,   \citep{Bertot:2004:ITP} \citep{Chlipala:2013:CPD:2584504}
 can be referred, and for cryptography,    \citep{Menezes:1996:HAC:548089} \citep{Schneier:1995:ACP:212584} \citep{Paar:2009:UCT:1721909} 
can be referred.  In the next chapter, we will discuss the Schulze method, the machinery needed for formalization. 




